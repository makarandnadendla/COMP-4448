{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "1160e89ee7146e19f5a8bab966c84b7d3ad1814cc8b7f70dc73638377f79cd89"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# K Nearest Neighbors\n",
    "University of Denver\n",
    "\n",
    "Makarand Nadendla"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           workclass   education    race   gender  income\n",
       "0          State-gov   Bachelors   White     Male   <=50K\n",
       "1   Self-emp-not-inc   Bachelors   White     Male   <=50K\n",
       "2            Private     HS-grad   White     Male   <=50K\n",
       "3            Private        11th   Black     Male   <=50K\n",
       "4            Private   Bachelors   Black   Female   <=50K"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>workclass</th>\n      <th>education</th>\n      <th>race</th>\n      <th>gender</th>\n      <th>income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>State-gov</td>\n      <td>Bachelors</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Self-emp-not-inc</td>\n      <td>Bachelors</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Private</td>\n      <td>HS-grad</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Private</td>\n      <td>11th</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Private</td>\n      <td>Bachelors</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "df_income_evaluation_cat = pd.read_csv(\"income_evaluation_cat.csv\")\n",
    "df_income_evaluation_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']\n\n[' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th']\n\n[' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other']\n\n[' Male' ' Female']\n\n[' <=50K' ' >50K']\n\n"
     ]
    }
   ],
   "source": [
    "for var in df_income_evaluation_cat.columns.values:\n",
    "    print(df_income_evaluation_cat[var].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\" Private\",\" Bachelors\",\" White\", \" Female\"]"
   ]
  },
  {
   "source": [
    "So the Bayes Theorom would be:\n",
    "\n",
    "P(Yi/x) = P(X/Yi)*P(Yi)\n",
    "then find the max of the P(Yi/X) and select your answer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_bayes_cat(training, test, outcome_col):\n",
    "    \n",
    "    post_probability = {}\n",
    "    \n",
    "    for outcome in training[outcome_col].unique():\n",
    "        p_yi = training[outcome_col].value_counts()[outcome]/training.shape[0]\n",
    "        p_x_yi = 1\n",
    "        \n",
    "        # p_x_yi calculations\n",
    "        training_yi = training[training[outcome_col] == outcome]\n",
    "        for i,x in enumerate(test):\n",
    "            partial_prob = sum(training_yi.iloc[:,i] == x)/training_yi.shape[0]\n",
    "            p_x_yi = p_x_yi*partial_prob\n",
    "      \n",
    "        p_yi_x = p_x_yi*p_yi\n",
    "        post_probability[outcome]=p_yi_x\n",
    "    \n",
    "    pred = max(post_probability, key=post_probability.get)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' <=50K'"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "n_bayes_cat(df_income_evaluation_cat, X, ' income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income_evaluation_cat = pd.get_dummies(df_income_evaluation_cat, columns=[\" workclass\",\" education\",\" race\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_income_evaluation_cat.drop(\" income\", axis = 1),df_income_evaluation_cat[\" income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = CategoricalNB()\n",
    "NB.fit(X_train, y_train)\n",
    "y_test_pred = NB.score(X_test,y_test)\n",
    "y_train_pred = NB.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7791426114727921 0.7875921375921376\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            age  education_num  hours_per_week\n",
       "mean  38.581647      10.080679       40.437456\n",
       "std   13.640433       2.572720       12.347429"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>education_num</th>\n      <th>hours_per_week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>38.581647</td>\n      <td>10.080679</td>\n      <td>40.437456</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>13.640433</td>\n      <td>2.572720</td>\n      <td>12.347429</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "df_income_evaluation_cont = pd.read_csv(\"income_evaluation_continuous.csv\")\n",
    "df_income_evaluation_cont.apply(func = [\"mean\",\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [30, 10, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_bayes_cont(training, test, outcome_col):\n",
    "    \n",
    "    post_probability = {}\n",
    "    \n",
    "    for outcome in training[outcome_col].unique():\n",
    "        p_yi = training[outcome_col].value_counts()[outcome]/training.shape[0]\n",
    "        p_x_yi = 1\n",
    "        \n",
    "        # p_x_yi calculations\n",
    "        training_yi = training[training[outcome_col] == outcome]\n",
    "        for i,x in enumerate(test):\n",
    "            mean = np.mean(training_yi.iloc[:,i])\n",
    "            std = np.std(training_yi.iloc[:,i])\n",
    "            partial_prob = norm.pdf(x, mean, std)\n",
    "            p_x_yi = p_x_yi*partial_prob\n",
    "      \n",
    "        p_yi_x = p_x_yi*p_yi\n",
    "        post_probability[outcome]=p_yi_x\n",
    "\n",
    "    pred = max(post_probability, key=post_probability.get)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' <=50K'"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "n_bayes_cont(df_income_evaluation_cont, X, \" income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8011056511056511 0.7957253408672154\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_income_evaluation_cont.drop(\" income\", axis = 1),df_income_evaluation_cont[\" income\"])\n",
    "NB_model = Pipeline(steps = [(\"Scaler\", StandardScaler()),(\"Model\", GaussianNB())])\n",
    "NB_model.fit(X_train, y_train)\n",
    "print(NB_model.score(X_train, y_train), NB_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = pd.read_csv(\"True.csv\")\n",
    "df_true[\"news_type\"] = pd.Series(df_true.shape[0]*\"True\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = pd.read_csv(\"Fake.csv\")\n",
    "df_fake[\"news_type\"] = pd.Series(df_fake.shape[0]*\"Fake\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_true,df_fake])\n",
    "df_total[\"news\"] =  df_total[\"title\"] + \" \" + df_total[\"text\"]\n",
    "df_total[df_total[\"news\"].apply(lambda x: len(x) < 50)] \n",
    "df_total.drop(labels=[\"title\", \"text\"],axis=1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   date       subject  \\\n",
       "0             31-Dec-17  politicsNews   \n",
       "1             29-Dec-17  politicsNews   \n",
       "2             31-Dec-17  politicsNews   \n",
       "3             30-Dec-17  politicsNews   \n",
       "4             29-Dec-17  politicsNews   \n",
       "...                 ...           ...   \n",
       "23476  January 16, 2016   Middle-east   \n",
       "23477  January 16, 2016   Middle-east   \n",
       "23478  January 15, 2016   Middle-east   \n",
       "23479  January 14, 2016   Middle-east   \n",
       "23480  January 12, 2016   Middle-east   \n",
       "\n",
       "                                                    news news_type  \n",
       "0      As U.S. budget fight looms, Republicans flip t...      True  \n",
       "1      U.S. military to accept transgender recruits o...      True  \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...      True  \n",
       "3      FBI Russia probe helped by Australian diplomat...      True  \n",
       "4      Trump wants Postal Service to charge 'much mor...      True  \n",
       "...                                                  ...       ...  \n",
       "23476  McPain: John McCain Furious That Iran Treated ...      Fake  \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...      Fake  \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...      Fake  \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...      Fake  \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...      Fake  \n",
       "\n",
       "[44898 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>subject</th>\n      <th>news</th>\n      <th>news_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31-Dec-17</td>\n      <td>politicsNews</td>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29-Dec-17</td>\n      <td>politicsNews</td>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31-Dec-17</td>\n      <td>politicsNews</td>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30-Dec-17</td>\n      <td>politicsNews</td>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29-Dec-17</td>\n      <td>politicsNews</td>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23476</th>\n      <td>January 16, 2016</td>\n      <td>Middle-east</td>\n      <td>McPain: John McCain Furious That Iran Treated ...</td>\n      <td>Fake</td>\n    </tr>\n    <tr>\n      <th>23477</th>\n      <td>January 16, 2016</td>\n      <td>Middle-east</td>\n      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n      <td>Fake</td>\n    </tr>\n    <tr>\n      <th>23478</th>\n      <td>January 15, 2016</td>\n      <td>Middle-east</td>\n      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n      <td>Fake</td>\n    </tr>\n    <tr>\n      <th>23479</th>\n      <td>January 14, 2016</td>\n      <td>Middle-east</td>\n      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n      <td>Fake</td>\n    </tr>\n    <tr>\n      <th>23480</th>\n      <td>January 12, 2016</td>\n      <td>Middle-east</td>\n      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n      <td>Fake</td>\n    </tr>\n  </tbody>\n</table>\n<p>44898 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "df_total = df_total.reindex([\"date\",\"subject\",\"news\",\"news_type\"], axis = 1)\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contraction_replacer(object):\n",
    "    def __init__(self, contraction_patterns):\n",
    "        self._contraction_regexes = [(re.compile(p), replaced_text) for p, replaced_text in contraction_patterns]\n",
    "\n",
    "    def do_contraction_normalization(self, text):\n",
    "        for contraction_regex, replaced_text in self._contraction_regexes:\n",
    "            text = contraction_regex.sub(replaced_text, text)\n",
    "        return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    edited_contraction_patterns = [(r'won\\'t', 'will not'), (r'can\\'t', 'cannot'),\n",
    "    (r'haven\\'t', 'have not'),\n",
    "    (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "    (r'(\\w+)\\'re', '\\g<1> are'), (\",\",\"\"), (\"'\",\"\")]\n",
    "\n",
    "    replacer = contraction_replacer(edited_contraction_patterns)\n",
    "    text = replacer.do_contraction_normalization(text)\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    # lemmatization\n",
    "    wnlemma = WordNetLemmatizer()\n",
    "    lemma_text = []\n",
    "    for word in text:\n",
    "        if word in string.punctuation:\n",
    "            continue\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        lemma_text.append(wnlemma.lemmatize(word))\n",
    "    lemma_text = \" \".join(lemma_text)\n",
    "\n",
    "    return lemma_text\n",
    "\n",
    "df_total[\"news\"] = df_total[\"news\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "df_total_subset = df_total.sample(5000)\n",
    "X = vectorizer.fit_transform(df_total_subset[\"news\"]).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_total_subset[\"news_type\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9614285714285714 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "print(NB_model.score(X_train, y_train), NB_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9414 0.0072691127381544806\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(NB_model, X, df_total_subset[\"news_type\"], cv=10)\n",
    "print(np.mean(cv_results['test_score']), np.std(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alpha': 0.4, 'fit_prior': False}"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "search = GridSearchCV(NB_model, param_grid={\"alpha\":[k for k in np.linspace(0,1.0,num=11)], \"fit_prior\":[True,False]})\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football = pd.read_csv(\"football_feed_df_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football= df_football[[\"full_text\",\"team\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_football.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "#df_football_subset = df_football.sample(5000)\n",
    "df_football[\"full_text\"].apply(preprocess_text)\n",
    "X = vectorizer.fit_transform(df_football[\"full_text\"]).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_football[\"team\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9494917407878017 0.7422222222222222\n"
     ]
    }
   ],
   "source": [
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "print(NB_model.score(X_train, y_train), NB_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.968869123252859 0.7762962962962963\n"
     ]
    }
   ],
   "source": [
    "search = GridSearchCV(NB_model, param_grid={\"alpha\":[k for k in np.linspace(0,1.0,num=11)], \"fit_prior\":[True,False]})\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_\n",
    "print(search.score(X_train, y_train), search.score(X_test, y_test))"
   ]
  }
 ]
}